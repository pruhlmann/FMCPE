num_samples: 50000
rescale: "none" # handled is simulator
generation: "independent"
name: "pendulum"
num_cal: [10,50,200,1000]
max_cal: 1000000
naugment: 1

simulator:
  name: pendulum
  params:
    obs_dim: 200
    low_w0: 0.0
    high_w0: 3.0
    low_A: 0.5
    high_A: 10.0
    tmax: 10.0

### METHODS ###
fm_post_transform:
  config:
    npe: "npe"
    flow_x:
      space: "data"
      conditional: True
      probability_path: "ot2"
      prior: 'uniform'
      base_dist: 'data_eps'
      params:
        probability_path_params: {"sigma_min": 1e-4}
        base_dist_params: {"eps": 5e-2}
        drift:
          # architecture: 'resmlp'
          architecture: "cfnet"
          posterior_kwargs:
            input_dim: ${task.simulator.params.obs_dim}
            dropout: 0.0
            batch_norm: True
            context_dim: 10
            theta_with_glu: False
            context_with_glu: False
            activation: "gelu"
            hidden_dims: [32, 64, 128, 256, 512, 256, 128, 64, 32]
          theta_embedding_kwargs:
            name: "conv1d"
            time_emdedding: True
            output_dim: 10 # same as context_dim
            n_freqs: 5
          embedding_kwargs:
            name: "conv1d"
            output_dim: 10 # same as context_dim
    flow_theta:
      space: "data"
      conditional: True
      probability_path: "ot2"
      prior: 'uniform'
      base_dist: 'gaussian'
      params:
        probability_path_params: {"sigma_min": 1e-4}
        # prior_params: {"rate": 2.0}
        base_dist_params: {}
        drift:
          # architecture: 'resmlp'
          architecture: "cfnet"
          posterior_kwargs:
            input_dim: 2
            dropout: 0.0
            batch_norm: False
            context_dim: 10
            theta_with_glu: True
            context_with_glu: False
            activation: "gelu"
            hidden_dims: [32, 64, 128, 256, 256, 128, 64, 32]
          embedding_kwargs:
            name: "conv1d"
            output_dim: 10 # same as context_dim
  training_params:
    rescale: ${task.rescale}
    lr: 1e-3
    epochs: 300
    batch_size: 256
    max_patience: 10
    train_size: 0.8
### BASELINES ####

npe:
  training:
    lr: 1e-4
    batch_size: 256
    epochs: 2000
    train_size: 0.8
    max_patience: 20
    rescale: ${task.rescale}
  params:
    embedding_net:
      model_path: 'models'
      load: False
      save: 'last_'
      output_dim: 10
      image_size: ${task.simulator.params.obs_dim}
    npe_params:
      embedding_dim: 10
      ntransform: 1

fmpe:
  config:
    space: "data"
    conditional: True
    probability_path: "ot2"
    prior: 'power'
    base_dist: 'gaussian'
    params:
      probability_path_params: {"sigma_min": 1e-4}
      prior_params: {"rate": 2.0}
      base_dist_params: {}
      drift:
        # architecture: 'resmlp'
        architecture: "cfnet"
        posterior_kwargs:
          input_dim: 2
          dropout: 0.0
          batch_norm: False
          context_dim: 10
          theta_with_glu: True
          context_with_glu: False
          activation: "gelu"
          hidden_dims: [32, 64, 128, 256, 256, 128, 64, 32]
        embedding_kwargs:
          name: "conv1d"
          output_dim: 10 # same as context_dim
  training_params:
    rescale: ${task.rescale}
    lr: 1e-3
    epochs: 300
    batch_size: 256
    max_patience: 10
    train_size: 0.8
